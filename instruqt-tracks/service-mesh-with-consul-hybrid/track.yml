slug: service-mesh-with-consul-hybrid
id: akamvplbrcry
type: track
title: Service Mesh with Consul Hybrid
teaser: Connect disparate platforms across datacenters.
description: In this track you leverage Mesh Gateways to connect applications and
  services between K8s and VMs in remote datacenters.
icon: https://storage.googleapis.com/instruqt-frontend/assets/hashicorp/tracks/consul.png
tags: []
owner: hashicorp
developers:
- lance@hashicorp.com
private: true
published: true
show_timer: true
challenges:
- slug: connect-your-datacenters
  id: i8yrscsmhmjx
  type: challenge
  title: Connect your Datacenters
  teaser: Connect two DCs across a WAN network.
  assignment: |-
    Let's take a brief moment to review our environment. <br>

    In DC1, we have a VM running a Consul server.
    We also have a Kubernetes cluster running with a single worker node.
    This Kubernetes worker node has a Consul agent running on it with a DaemonSet. <br>

    We can see this below. <br>

    ```
    consul members
    ```

    In DC2, we have a VM running a Consul server.
    We also have a VM that will run our legacy service.
    We'll inspect this Consul cluster in the next section. <br>

    The lab is preconfigured for connectivity within each Consul DC, but we need to make each datacenter Consul aware of the other datacenter. <br>

    Let's do this by connecting our two Consul datacenters with a `wan join`.
    This will allow us to manage our workloads across the datacenters. <br>

    **Note**: the lab env helps us this with this resolution of short names for our lab servers.  <br>

    ```
    consul join -wan dc2-consul-server
    ```

    Now let's check our members output

    ```
    consul members -wan
    ```

    Great! Now that we have federation between our Consul datacenters, we can start deploying our workloads.
  notes:
  - type: text
    contents: |-
      In this track we will connect applications across two separate datacenters, with application components in each.
      Our lab datacenters will reflect a common heterogeneous environment.

      * DC1 - Kubernetes & VM Environment (greenfield)
      * DC2 - VM Environment (legacy)

      The two most common problems when connecting datacenters in this pattern are:

      1. Overlapping IP spaces
      2. Firewall complexities

      In this track we will show you how Consul Connect and Mesh Gateways can solve this problem. <br>

      We need a few minutes to spin up your K8s infrastructure.
  tabs:
  - title: DC1 - Consul
    type: terminal
    hostname: dc1-consul-server
  - title: DC1 - UI
    type: service
    hostname: dc1-consul-server
    path: /ui/dc1/nodes
    port: 8500
  - title: DC2 - UI
    type: service
    hostname: dc2-consul-server
    path: /ui/dc2/nodes
    port: 8500
  difficulty: basic
  timelimit: 900
- slug: deploy-your-legacy-app
  id: tllzuoxgzfbe
  type: challenge
  title: Deploy your Legacy App
  teaser: Deploy legacy services to your on-prem datacenter.
  assignment: |-
    Let's take a quick look at Consul in this DC. <br>

    ```
    consul members
    ```

    We have the Currency service running for you on the VM in DC2.
    You can see the app running in Docker. <br>

    ```
    docker ps -a
    ```

    Let's add a Consul health check for the service, and reload it.

    ```
    cat <<-EOF > /etc/consul.d/currency-service.json
    {
      "service": {
        "name": "currency",
        "tags": [
          "production"
        ],
        "port": 9094,
        "check": {
          "id": "http",
          "name": "traffic on port 9094",
          "http": "http://127.0.0.1:9094/health",
          "interval": "10s",
          "timeout": "1s"
        }
      }
    }
    EOF

    consul reload
    ```

    You should see a healthy service in Consul. We can also test this service locally.

    ```
    curl -s  http://127.0.0.1:9094 | jq
    ```

    Nice work! Now let's deploy the rest of our application in the other datacenter.
  notes:
  - type: text
    contents: |-
      We will use our tracing app from the previous track for this lab.
      As you recall, the app is broken out into five components:

      * Frontend - Access to our application
      * API - gRPC API to backend services
      * Cache - Cache responses for our API
      * Payments  - Process payments
      * Currency - Do currency lookups for our payments

      Our currency service will represent our legacy workload running on-prem in DC2.
  tabs:
  - title: DC2 - UI
    type: service
    hostname: dc2-consul-server
    path: /ui/dc2
    port: 8500
  - title: DC2 - App
    type: terminal
    hostname: dc2-app-server
  difficulty: basic
  timelimit: 900
- slug: deploy-the-modern-app
  id: 4ivf5ahd7jwv
  type: challenge
  title: Deploy the Modern App
  teaser: Deploy our application on K8s.
  assignment: |-
    We've made a few minor changes to the deployment spec from the last track.
    You'll notice we've removed the spec file for the `currency` service, as it's already running in DC2. <br>

    We've also removed the `sidecar` upstreams from the `payments` service that calls the currency service, replaced it with a _Consul DNS_ definition instead. <br>

    This is a common transition pattern where service discovery aware apps can become service mesh aware in a phased rollout.
    You can read more about this integration in K8s [here](https://www.consul.io/docs/platform/k8s/dns.html). <br>

    Check this out in the `payments.yml` deployment file. <br>

    ```
    - name: UPSTREAM_URIS
      value: "http://currency.service.dc2.consul:9094"
    ```

    Let's deploy the rest of the application and test it. Our frontend web component is accessible via NodePort.

    ```
    kubectl apply -f  tracing

    sleep 30

    kubectl wait --for=condition=Ready $(kubectl get pod --selector=app=web -o name)
    kubectl wait --for=condition=Ready $(kubectl get pod --selector=app=api -o name)
    kubectl wait --for=condition=Ready $(kubectl get pod --selector=app=cache -o name)
    kubectl wait --for=condition=Ready $(kubectl get pod --selector=app=payments -o name)
    ```

    Once all the pods are ready, we can send traffic to the frontend.

    ```
    curl -s localhost:30900 | jq
    ```

    Hmmm, it looks like something went wrong. You should see a similar timeout message. <br>

    ```
    rpc error: code = Internal desc = Error processing upstream request
    ```

    That error is not particularly helpful.
    Let's use our tracing infrastructure to run this down in the next assignment.
  notes:
  - type: text
    contents: Now that we have our legacy service running in DC2, let's deploy the
      rest of the application in DC1.
  tabs:
  - title: DC2 - UI
    type: service
    hostname: dc1-consul-server
    path: /ui/dc2
    port: 8500
  - title: DC1 - K8s
    type: terminal
    hostname: dc1-kubernetes
  - title: DC1 - UI
    type: service
    hostname: dc1-consul-server
    path: /ui/dc1
    port: 8500
  - title: DC1 - App Config
    type: code
    hostname: dc1-kubernetes
    path: /root/tracing
  difficulty: basic
  timelimit: 900
- slug: find-the-issue
  id: xeiyeagxgrqr
  type: challenge
  title: Find the Issue
  teaser: Something is not quite right...
  assignment: |-
    Let's revisit our Jaeger UI and take a look at the latest trace data.
    You should see a message similar to this  in the payments trace.
    You can get to this message quickly by clicking on the `expand all` button in Jaeger for the trace. <br>

    ```
    "error:Error communicating with upstream service: Get http://currency.service.dc2.consul:9094/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)"
    ```

    It seems even though we could discover the service in the datacenter, we don't actually have a route to that service, or the network is blocking it.

    Let's explore this further with a basic connectivity check between our K8s node and our server running in the other DC.
    We can use a tool called `nmap` to help us with this verification. <br>

    We know that IP is our Currency service running on our DC2 app server, so we can test with the below command. <br>

    ```
    ip=$(getent ahostsv4 dc2-app-server |  awk '{print $1}' | head -1)
    nmap -p 9094 $ip
    ```

    It looks like that route is indeed blocked. We can see the status as `filtered`. <br>

    Let's look at how Mesh Gateways can help us solve this problem in the next exercise.
  notes:
  - type: text
    contents: |-
      In this section we will investigate the connectivity issues between
      DCs. We'll wait a few moments for our traces to propagate.
  tabs:
  - title: DC1 - K8s
    type: terminal
    hostname: dc1-kubernetes
  - title: Jaeger UI
    type: service
    hostname: dc1-jaeger-server
    path: /search?service=web
    port: 16686
  difficulty: basic
  timelimit: 900
- slug: add-the-legacy-sidecar
  id: rtl3rsmtneic
  type: challenge
  title: Add the Legacy Sidecar
  teaser: Bring our legacy service into the mesh
  assignment: |-
    Let's start by updating consul with a sidecar service definition. <br>

    ```
    cat <<-EOF > /etc/consul.d/currency-service.json
    {
      "service": {
        "name": "currency",
        "tags": [
          "production"
        ],
        "port": 9094,
        "connect": { "sidecar_service": {} },
        "check": {
          "id": "http",
          "name": "traffic on port 9094",
          "http": "http://127.0.0.1:9094/health",
          "interval": "10s",
          "timeout": "1s"
        }
      }
    }
    EOF

    consul reload
    ```

    Now we can start our sidecar.

    ```
    nohup consul connect envoy -sidecar-for=currency > /envoy.out &
    ```

    Excellent. Now let's create our gateways.
  notes:
  - type: text
    contents: To make our legacy service work with the mesh gateways, we need to run
      a proxy next to the service, which we will deploy in this assignment.
  tabs:
  - title: DC2 - App
    type: terminal
    hostname: dc2-app-server
  - title: DC2 - UI
    type: service
    hostname: dc1-consul-server
    path: /ui/dc2
    port: 8500
  difficulty: basic
  timelimit: 900
- slug: deploy-the-dc2-gateway
  id: gl8vtewtwevq
  type: challenge
  title: Deploy the DC2 Gateway
  teaser: Connect our Gateway to our legacy app
  assignment: |-
    We have introduced a new server that will represent ingress and egress points for DC2.
    Let's do some basic connectivity checks before we make Consul aware of our gateway nodes. <br>

    Let's first check our gateway in DC2 can reach the local app.
    We'll use some helpful resolution from the lab env to grab the same IP from our Jaeger trace. <br>

    ```
    ip=$(getent ahostsv4 dc2-app-server |  awk '{print $1}' | head -1)
    nmap -p 9094 $ip
    ```

    It looks like our Gateway server in DC2 has a direct route to our application.
    We can see this with the state of `open`. Progress!

    Now we can configure the node to be a mesh gateway and bring it into our mesh.
    There is a Consul agent already running on this machine. <br>

    ```
    local_ipv4=$(curl -s -H "Metadata-Flavor: Google" http://metadata/computeMetadata/v1/instance/network-interfaces/0/ip)
    nohup consul connect envoy -mesh-gateway -register \
                     -service "gateway" \
                     -address ${local_ipv4}:443 \
                     -wan-address ${local_ipv4}:443 \
                     -bind-address "public=${local_ipv4}:443" \
                     -admin-bind 127.0.0.1:19000 > /gateway.out &
    ```
    Now we've got our gateway running we can see we have a listener for this traffic.

    ```
    curl localhost:19000/listeners
    ```

    Let's repeat this deployment in DC1.
  notes:
  - type: text
    contents: |-
      In the last assignment we discovered our Kubernetes cluster in DC1 was not able to route to our legacy app running in DC2.
      This is a common problem, and in general these types of routes can be tricky to set up and secure. <br>

      In this lab we will deploy a Mesh Gateway in DC2 and establish connectivity between the gateway and our service.
  tabs:
  - title: DC2 - Gateway
    type: terminal
    hostname: dc2-consul-gateway
  - title: DC2 - UI
    type: service
    hostname: dc1-consul-server
    path: /ui/dc2
    port: 8500
  difficulty: basic
  timelimit: 900
- slug: deploy-the-dc1-gateway
  id: ilvgq6nayfv6
  type: challenge
  title: Deploy the DC1 Gateway
  teaser: Establish gateway connectivity across datacenters
  assignment: |-
    First, let's check our connectivity again.
    We can check this between gateways now that our DC2 gateway is accepting traffic. <br>

    Let's check the gateway to the DC2 app server first.

    ```
    ip=$(getent ahostsv4 dc2-app-server |  awk '{print $1}' | head -1)
    nmap -p 9094 $ip
    ```

    Let's check the gateway in DC1 to the gateway in DC2.

    ```
    ip=$(getent ahostsv4 dc2-consul-gateway |  awk '{print $1}' | head -1)
    nmap -p 443 $ip
    ```

    Our gateway can reach the other gateway, but not the app server.
    This is the behavior we expect based on our lab environment.
    The gateways will handle all the cross DC traffic, so we don't have to worry about it. <br>

    Now let's start up the Gateway in DC1.
    There is a preconfigured Consul agent on this box. <br>

    ```
    local_ipv4=$(curl -s -H "Metadata-Flavor: Google" http://metadata/computeMetadata/v1/instance/network-interfaces/0/ip)
    nohup consul connect envoy -mesh-gateway -register \
                     -service "gateway" \
                     -address ${local_ipv4}:443 \
                     -wan-address ${local_ipv4}:443 \
                     -bind-address "public=${local_ipv4}:443" \
                     -admin-bind 127.0.0.1:19000 > /gateway.out &
    ```

    We can now verify our new listener.

    ```
    curl localhost:19000/listeners
    ```

    Now that we have gateway to gateway connectivity, let's fix our app and redeploy it to use the sidecars across gateways.
  notes:
  - type: text
    contents: Now that we have a Gateway in DC2 that can talk to our legacy service,
      we can spin up a gateway in DC1, and connect the two gateways.
  tabs:
  - title: DC1 - Gateway
    type: terminal
    hostname: dc1-consul-gateway
  - title: DC1 - UI
    type: service
    hostname: dc1-consul-server
    path: /ui/dc1
    port: 8500
  - title: DC2 - UI
    type: service
    hostname: dc1-consul-server
    path: /ui/dc2
    port: 8500
  difficulty: basic
  timelimit: 900
- slug: bring-it-all-together
  id: z1mn5uy8ougt
  type: challenge
  title: Bring it all Together
  teaser: You're first multi-dc mesh
  assignment: |-
    First, let's set up tcpdump to inspect the traffic on our gateways. <br>

    On the DC1 gateway, run the following. This filter looks specifically at the SSL handshake hello packet. <br>

    ```
    tcpdump -i ens4 -s 1500 '(tcp[((tcp[12:1] & 0xf0) >> 2)+5:1] = 0x01) and (tcp[((tcp[12:1] & 0xf0) >> 2):1] = 0x16)' -nnXSs0 -ttt
    ```

    On the DC2 gateway, run the following.  We'll look at all the packets.

    ```
    tcpdump -i ens4 port 443 -nnXX -vv -A
    ```


    You'll notice the upstream definition has an a datacenter tag appended to the upstream, for `dc2`. You can see this in the code editor.
    We've set the gateways up in [local](https://www.consul.io/docs/connect/mesh_gateway.html#local) mode so this will send all cross DC traffic through our gateways. <br>

    ```
    "consul.hashicorp.com/connect-service-upstreams": "currency:9094:dc2"
    ```

    Now we can redeploy our app on the `DC1 - K8s` tab.

    ```
    kubectl apply -f tracing
    sleep 10
    kubectl wait --for=condition=Ready $(kubectl get pod --selector=app=payments -o name)
    ```

    Next, let's simulate some traffic through the `DC1 - K8s` tab.

    ```
    curl -s localhost:30900 | jq
    ```

    Awesome. You've fixed the application across DCs!! Go check out the new Jaeger traces!! <br>

    If you look closely at the packets in the `DC1 - Gateway` tab you'll see a a similar value that is not encrypted.

    ```
    currency.default.dc2.internal.<domain>.consul
    ```

    That's the SNI header. It's the **only** piece of information the gateway can see, and this value allows it to be sent to the correct destination. <br>

    The packet is not decrypted until it reaches the last sidecar proxy, so we have end-to-end encryption across over the WAN between our DCs. <br>

    Nice work!!! You just ran your first Mesh Gateway workload!!!
  notes:
  - type: text
    contents: |-
      Now that we have gateways to connect our DCs, we can redeploy our application, and route the entire component flow through the sidecars and gateways.
      We'll inspect some of the traffic through the gateways to validate they are being used, and look specifically at the **SNI** headers, as well as trace data. <br>
  tabs:
  - title: DC2 - Gateway
    type: terminal
    hostname: dc2-consul-gateway
  - title: DC1 - App Config
    type: code
    hostname: dc1-kubernetes
    path: /root/tracing/payments.yml
  - title: DC1 - K8s
    type: terminal
    hostname: dc1-kubernetes
  - title: DC1 - Gateway
    type: terminal
    hostname: dc1-consul-gateway
  - title: Jaeger UI
    type: service
    hostname: dc1-jaeger-server
    path: /search?service=web
    port: 16686
  difficulty: basic
  timelimit: 900
- slug: failover-the-app
  id: 9zu9yzfvwsbh
  type: challenge
  title: Test a Failover
  teaser: Migrate a legacy app with DC failover
  assignment: |-
    Remember, these gateways operate by sniffing the [SNI header](https://en.wikipedia.org/wiki/Server_Name_Indication) out of the Connect session,
    and then routing the connection to the appropriate destination based on the server name requested.
    The mesh gateways we deployed in the previous assignments will handle the WAN traversal.
    You will introspect SNI values throughout the failover workflow. <br>

    First, deploy all application components to the new DC, DC1.

    ```
    kubectl apply -f tracing
    ```

    Now, verify you have the currency service running in both DCs.
    You can check the in the UI or use the API.

    ```
    curl -s 'http://127.0.0.1:8500/v1/health/service/currency?passing=true&dc=dc1' | jq
    curl -s 'http://127.0.0.1:8500/v1/health/service/currency?passing=true&dc=dc2' | jq
    ```

    Now that you have healthy services in both DCs you can create a failover config.

    ```
    cat <<EOF | consul config write -
    kind            = "service-resolver"
    name            = "currency"
    connect_timeout = "3s"
    failover = {
      "*" = {
        datacenters = ["dc2"]
      }
    }
    EOF
    consul config read -kind service-resolver -name currency
    ```

    Consul keeps track of the health of these services in both DCs.
    If the service is not available in the local DC, the data plane will update in real time, and route to the other DC.
    Let's explore this further.  <br>


    The payment service has the currency service in its upstream configuration.
    Notice there is no explicit datacenter definition specified in the K8s deployment file.
    The [central config](https://www.consul.io/docs/agent/config_entries.html) you added earlier will handle this transparently for the developer. <br>

    ```
    cat tracing/payments.yml  | grep "consul.hashicorp.com/connect-service-upstreams"
    ```

    Let's inspect the data plane while our currency container is healthy in DC1.
    You will also compare the IP with Consul's registry.
    The cluster IP address will match the POD IP value in the catalog.
    The SNI value will be for DC1. <br>

    ```
    curl -s localhost:8500/v1/catalog/service/currency?dc=dc1 | jq '[.. |."ServiceAddress"? | select(. != null)]'
    kubectl exec $(kubectl get pod --selector=app=payments -o name) -c consul-connect-envoy-sidecar -- wget -qO- localhost:19000/clusters
    kubectl exec $(kubectl get pod --selector=app=payments -o name) -c consul-connect-envoy-sidecar -- wget -qO- localhost:19000/config_dump | jq '[.. |."dynamic_active_clusters"? | select(. != null)[0]]'
    ```

    When you're done comparing the values, send some traffic to the frontend service,
    and inspect the Jaeger traces. Look for the `process IP` in the trace for the currency service. <br>

    ```
    curl -s localhost:30900 | jq
    ```

    Now you can simulate a failure by stopping the deployment in DC1.

    ```
    kubectl delete -f tracing/currency.yml
    ```

    The gateway is running in [local mode](https://www.consul.io/docs/connect/mesh_gateway.html#local), so the value in the data plane will update to the gateway server in the local DC.
    The SNI value for that Envoy cluster has also changed. It will now point to `dc2`.
    The mesh gateway will use this value to send traffic to the correct destination DC.
    You can validate each of these below.

    ```
    curl -s localhost:8500/v1/catalog/service/gateway?dc=dc1 | jq '[.. |."ServiceAddress"? | select(. != null)]'
    kubectl exec $(kubectl get pod --selector=app=payments -o name) -c consul-connect-envoy-sidecar -- wget -qO- localhost:19000/clusters
    kubectl exec $(kubectl get pod --selector=app=payments -o name) -c consul-connect-envoy-sidecar -- wget -qO- localhost:19000/config_dump | jq '[.. |."dynamic_active_clusters"? | select(. != null)[0]]'
    ```

    Optionally, you can look at the packets flowing through the mesh gateways.
    Run the below command on the two gateway tabs:
      * DC1 - Gateway
      * DC2 - Gateway

    ```
    tcpdump -i ens4 port 443 -nnXX -vv -A
    ```

    Now, send some traffic to the frontend service,
    and inspect the Jaeger traces. Look for the `process IP` in the trace for the currency service.

    ```
    curl -s localhost:30900 | jq
    ```

    Nice work!! You just did your first application failover with Consul.
  notes:
  - type: text
    contents: |-
      Let's revisit the last few assignments with a common deployment scenario and simulate a failover. <br>

      The legacy service is undergoing a migration to the new DC, DC1.
      The application will continue to run in the old DC, DC2, during this transition.
      In the event the newly migrated application fails, traffic will seamlessly route back to DC2. <br>
  tabs:
  - title: DC1 - K8s
    type: terminal
    hostname: dc1-kubernetes
  - title: DC1 - UI
    type: service
    hostname: dc1-consul-server
    path: /ui/dc1
    port: 8500
  - title: DC2 - UI
    type: service
    hostname: dc1-consul-server
    path: /ui/dc2
    port: 8500
  - title: Jaeger UI
    type: service
    hostname: dc1-jaeger-server
    path: /search?service=web
    port: 16686
  - title: DC1 - Gateway
    type: terminal
    hostname: dc1-consul-gateway
  - title: DC2 - Gateway
    type: terminal
    hostname: dc2-consul-gateway
  - title: DC2 - App
    type: terminal
    hostname: dc2-app-server
  - title: DC1 - App Config
    type: code
    hostname: dc1-kubernetes
    path: /root/tracing
  difficulty: basic
  timelimit: 300
checksum: "10467411493478919410"
